# -*- coding: utf-8 -*-
"""Machine_Learning_Recommendation_System_Submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WZyBz-qCDlY5K2ILiHAqyCKVCW3L9cgV

**Membuat Sistem Rekomendasi Film Menggunakan Machine Learning**

---
Sistem ini dibuat untuk memenuhi tugas Submission Kelas Machine Learning Terapan yang difasilitasi oleh Kementerian Pariwisata dan Ekonomi Kreatif (Kemenparekraf) bekerjasama dengan Dicoding.

---
Untuk membuat sistem rekomendasi film menggunakan machine learning, pertama import library dan module yang dibutuhkan.
"""

import os
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
from sklearn.feature_extraction.text import TfidfVectorizer
from tensorflow import keras
from tensorflow.keras import layers
from numpy import sqrt
from sklearn.metrics import mean_squared_error

"""**Install library Kaggle**

---

Menginstal library tambahan yang dibutuhkan. Dalam hal ini, library Kaggle yang nantinya akan digunakann untuk load dataset dari situs Kaggle
"""

!pip install kaggle

"""**Mount Google Drive Ke Dalam Google Colab**

---
Memberikan izin akses Google Colab untuk menggunakan Google Drive. Tujuannya, Agar dataset yang telah di download dari situs Kaggle tidak hilang saat session timeout, karena dataset tersebut telah disimpan pada Google Drive.
"""

drive.mount('/content/gdrive')

"""**Pengatur Path Penyimpanan Dataset**

---
Mengatur path (direktori/folder) yang akan digunakan dalam penyimpanan dataset.
"""

# Commented out IPython magic to ensure Python compatibility.
os.environ['KAGGLE_CONFIG_DIR'] = '/content/gdrive/MyDrive/recommendation'
# %cd /content/gdrive/MyDrive/recommendation

"""**Download Dataset**

---
Download dataset dari situs Kaggle untuk digunakan dalam pembuatan Recommendation System
"""

!kaggle datasets download -d hariprabu/imdb-1000

"""**Ekstrak Dataset**

---
Ekstrak dataset yang masih dalam file .zip
"""

!unzip /content/gdrive/MyDrive/recommendation/imdb-1000.zip

"""**Load Dataset**

---
Dataset yang telah tersedia di Google Drive, kemudian di load untuk dianalisis lebih lanjut.
"""

movies = pd.read_csv('/content/gdrive/MyDrive/recommendation/movies.csv')
ratings = pd.read_csv('/content/gdrive/MyDrive/recommendation/ratings.csv')

print('Jumlah film dalam dataset movies: ', len(movies.movieId.unique()))
print('Jumlah user yang memberikan rating: ', len(ratings.userId.unique()))

"""**Memeriksa Nama Variabel dan Missing Value Dataset movies**

---
Memeriksa nama variabel yang digunakan pada dataset movies serta missing valuenya.
"""

movies.info()

"""**Memeriksa Nama Variabel dan Missing Value Dataset ratings**

---
Memeriksa nama variabel yang digunakan pada dataset ratings dan missing valuenya.
"""

ratings.info()

"""**Menggabungkan Dataset movies dan ratings**

---
Agar dataset dapat dianalisis dengan menggunakan pendekatan Content Based Filtering dan Collaborative Filtering, maka dataset Movies dan Ratings harus digabungkan.
"""

movies_with_ratings = pd.concat([movies, ratings])
movies_with_ratings = pd.merge(movies, ratings, on='movieId', how='left')
movies_with_ratings

"""**Memeriksa Kembali Missing Value Dataset Gabungan**

---
Memeriksa kembali missing value dataset gabungan antara movies dan ratings.

"""

movies_with_ratings.isnull().sum()

"""**Membuang Missing Value**

---
Membuang missing value yang muncul setelah penggabungan dataset movies dan ratings

"""

movies_with_ratings = movies_with_ratings.dropna()
movies_with_ratings.isnull().sum()

"""**Membuang Data Duplikat**

---
Membuang data duplikat yang terdapat pada dataframe movies_with_ratings.
"""

movies_with_ratings = movies_with_ratings.drop_duplicates('movieId')
movies_with_ratings

"""**Melihat Detail Dataset**

---
Melihat detail dataset yang digunakan dengan menggunakan describe()
"""

movies_with_ratings.describe()

"""**Mencari Outliers**

---
Untuk mencari data yang bias pada set, kita akan mencari outliers pada variabel rating. Alasannya, karena variable rating memungkinkan adanya penilaian yang bias terhadap kualitas suatu film.
"""

sns.boxplot(x=movies_with_ratings['rating'])

"""**Visualisasi Data**

---
Melakukan visualisasi data untuk melihat komposisi data pada variabel rating.
"""

count = movies_with_ratings['rating'].value_counts()
percent = 100*movies_with_ratings['rating'].value_counts(normalize=True)
df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df)
movies_with_ratings['rating'].hist(bins=20, figsize=(5,5))

"""**Membuat Data List Untuk Input Sistem Rekomendasi Content Based Filtering**

---
Untuk membuat sistem rekomendasi content based filtering, maka dibuat list yang berasal dari variabel movieId, title, genres.

"""

movieId = movies_with_ratings['movieId'].tolist()
title = movies_with_ratings['title'].tolist()
genres = movies_with_ratings['genres'].tolist()

print(len(movieId))
print(len(title))
print(len(genres))

"""**Membuat Dataframe dari List**

---
Membuat dataframe untuk sistem rekomendasi content based filtering dari list movieId, title dan genres.

"""

movie_content = pd.DataFrame({
    'id': movieId,
    'title': title,
    'genres': genres
})
movie_content

"""**Menggunakan TF-IDF Vectorizer**

---
Menggunakan TF-IDF Vectorizer untuk proses pembobotan nilai.

"""

# Inisialisasi penggunaan TF-IDF Vectorizer
tf = TfidfVectorizer()

# Mempelajari kata yang terdapat pada movie_content['Genres']
tf.fit(movie_content['genres'])

# Tampilkan kata-kata yang telah dipelajari
tf.get_feature_names_out()

"""**Melakukan Data Fit dan Mengubah kedalam Bentuk Matrix**

---
Melakukan Data Fit hasil TF-IDF dan Mengubah kedalam Bentuk Matrix.

"""

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(movie_content['genres']) 

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

"""**Mengubah Sparse Matrix Menjadi Dense Matrix**

---
Mengubah sparse Matrix ke dalam bentuk dense matrix.

"""

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""**Menampilkan Dataframe yang telah diolah**
---
Menampilkan dataframe yang telah dilakukan pengolahan data.

"""

# Menampilkan Dataframe
pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names_out(),
    index=movie_content.title
).sample(15, axis=1).sample(10, axis=0)

"""**Menghitung Cosine Similarity**

---
Menghitung derajat kesamaan dengan menggunakan cosine similarity.
"""

from sklearn.metrics.pairwise import cosine_similarity
 
# Menghitung cosine similarity pada matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""**Membuat Dataframe dari Hasil Cosine Similarity**

---
Membuat Dataframe dari Hasil Cosine Similarity untuk mengetahui perbandingan derajat kesamaan,

"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_content['title'], columns=movie_content['title'])
print('Shape:', cosine_sim_df.shape)
 
cosine_sim_df.sample(5, axis=1).sample(5, axis=0)

"""**Membuat Function Untuk Content Based Filtering**

---
Membuat function dengan menggunakan bahasa python untuk membuat sistem rekomendasi Content Based Filtering.
"""

def movie_recommendation_CBF(title, similarity_data=cosine_sim_df, items=movie_content[['title', 'genres']], k=5):
   
    index = similarity_data.loc[:,title].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    closest = closest.drop(title, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

"""**Mencoba Hasil Sistem Rekomendasi Content Based Filtering**

---
Mencoba Hasil Sistem Rekomendasi Content Based Filtering dengan menginput judul film Ace Ventura: When Nature Calls (1995).

"""

movie_recommendation_CBF('Ace Ventura: When Nature Calls (1995)')

"""**Memeriksa keakuratan Hasil Sistem Rekomendasi**

---
Untuk memeriksa, keakuratan hasil sistem rekomendasi Content Based Learning, kita memeriksa genre dari judul film yang diinput.
"""

movie_content[movie_content.title.eq('Ace Ventura: When Nature Calls (1995)')]

"""**Data Preparation Untuk Sistem Rekomendasi Collaborative Filtering**

---
Melakukan proses Data Preparation Untuk Sistem Rekomendasi Collaborative Filtering dengan cara menyiapkan data Id Pengguna
"""

# Mengubah data id_pengguna menjadi list tanpa nilai duplikat
id_pengguna = ratings['userId'].unique().tolist()
print('Daftar id_pengguna: ', id_pengguna)
 
# Melakukan proses encoding id_pengguna
encoding_id_pengguna = {x: i for i, x in enumerate(id_pengguna)}
print('id_pengguna diencoding : ', encoding_id_pengguna)
 
# Melakukan proses encoding angka ke ke id_pengguna
user_encoding_to_user = {i: x for i, x in enumerate(id_pengguna)}
print('encoding angka ke id_pengguna: ', encoding_id_pengguna)

"""**Data Preparation Untuk Variabel movieId**

---
Melakukan proses data preparation pada variabel movieId, agar data dapat digunakan pada sistem rekomendasi Collaborative Filtering.
"""

# Mengubah id_film menjadi list tanpa duplikat
id_film = ratings['movieId'].unique().tolist()
 
# Melakukan proses encoding id_film
encoding_id_film = {x: i for i, x in enumerate(id_film)}
 
# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(id_film)}
 
# Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.
 
# Mapping userId ke dataframe genres
ratings['genres'] = ratings['userId'].map(encoding_id_pengguna)
 
# Mapping movieId ke dataframe movies
ratings['movies'] = ratings['movieId'].map(encoding_id_film)

"""**Menganalisis Data Untuk Collaborative Filtering**

---
Melakukan analisis data untuk Collaborative Filtering.
"""

total_users = len(encoding_id_pengguna)
print(total_users)
 
total_movies = len(movie_encoded_to_movie)
print(total_movies)
 
ratings['ratings'] = ratings['rating'].values.astype(np.float32)
 
min_rating = min(ratings['rating'])
 
max_rating = max(ratings['rating'])
 
print('Jumlah pengguna: {}, Jumlah Film: {}, Rating Minimal: {}, Rating Maksimal: {}'.format(
    total_users, total_movies, min_rating, max_rating
))

"""**Menetapkan Random State Untuk Dataframe**

---
Menetapkan Random State Pada Dataframe yang akan digunakan pada sistem rekomendasi Collaborative Filtering.
"""

df = ratings.sample(frac=1, random_state=40)
df

"""**Membagi Data Train dan Data Validasi**

---
Membuat variabel x dan y untuk membagi data train dan data validasi pada dataset yang digunakan.
"""

x = df[['genres', 'movies']].values
 
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
# Membagi dataset menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""**Membuat Fungsi Untuk Collaborative Filtering**

---
Membuat fungsi dengan menggunakan bahasa python untuk sistem rekomendasi Collaborative Filtering.
"""

class RecommenderNet(tf.keras.Model):
 
  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movies bias
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4
 
    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2) 
 
    x = dot_user_movie + user_bias + movie_bias
    
    return tf.nn.sigmoid(x) # activation sigmoid

"""**Melakukan Compile data**

---
Melakukan compile data untuk persiapan proses pelatihan data.
"""

model = RecommenderNet(total_users, total_movies, 50)
 
# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**Proses Pelatihan Data**

---
Proses Pelatihan data sebanyak 100 epoch.
"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**Visualisasi Hasil Pelatihan Data**

---
Visualisasi metriks hasil pelatihan data dengan melihat metrik root_mean_squared_error dan metrik val_root_mean_squared_error.

"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""**Persiapan Proses Penggunakan Sistem Collaborative Filtering**

---
Melakukan Persiapan Proses Penggunakan Sistem Collaborative Filtering.
"""

movie_df = movie_content
df = pd.read_csv('/content/gdrive/MyDrive/recommendation/ratings.csv')
 

user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]
 

movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id'] 
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(encoding_id_film.keys()))
)
 
movie_not_watched = [[encoding_id_film.get(x)] for x in movie_not_watched]
user_encoder = encoding_id_pengguna.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""**Mencoba Hasil Sistem Rekomendasi Collaborative Filtering**

---
Mencoba Hasil Sistem Rekomendasi Collaborative Filtering.
"""

ratings = model.predict(user_movie_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]
 
print('Menampilkan Rekomendasi Untuk User: {}'.format(user_id))
print('===' * 9)
print('Judul Film yang Memiliki Rating Tinggi dari User')
print('----' * 8)
 
top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)
 
movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.title, ':', row.genres)
 
print('----' * 8)
print('Top 10 Rekomendasi Film')
print('----' * 8)
 
recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.title, ':', row.genres)

"""**Nilai 10% RMSE Untuk Evaluasi Metrik**

---
- Untuk mengukur ketepatan sistem dalam memberikan rekomendasi film sesuai dengan perilaku user, didapatkan bahwa nilai 10% RMSE, yaitu 0.3029659363385887 
- Nilai RMSE error yang didapat pada hasil pelatihan model, yaitu 0.1948 (pada saat training) dan 0.2058 (pada saat validasi).
- Berdasarkan metrik tersebut, maka model sudah dapat dikatakan Good Fit.
"""

rmse_target = sqrt(mean_squared_error(y, ratings['rating']))
rmse_target = 0.1 * rmse_target
rmse_target